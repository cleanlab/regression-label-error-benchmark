{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File './../../../dataset/stanford_politeness_wiki_random.csv' already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ./../../../dataset/ -nc https://cleanlab-public.s3.amazonaws.com/RegressionBenchmark/stanford_politeness_wiki_random.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:  (1311, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meta.Binary</th>\n",
       "      <th>true_label</th>\n",
       "      <th>given_label</th>\n",
       "      <th>true_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't spend too much time, and I'm no specia...</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;url&gt;. I wonder if anyone will actually suspec...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok, that's no problem. Can you recommend any o...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well, that was an example as I am adding Infob...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi, i saw in a lot of biography articles are u...</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  meta.Binary  true_label  \\\n",
       "0  I can't spend too much time, and I'm no specia...            0        17.0   \n",
       "1  <url>. I wonder if anyone will actually suspec...            0        13.0   \n",
       "2  Ok, that's no problem. Can you recommend any o...            1        17.0   \n",
       "3  Well, that was an example as I am adding Infob...            0        13.0   \n",
       "4  Hi, i saw in a lot of biography articles are u...            0        17.0   \n",
       "\n",
       "   given_label  true_error  \n",
       "0           14           0  \n",
       "1           13           0  \n",
       "2           19           0  \n",
       "3           13           0  \n",
       "4           13           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./../../../dataset/stanford_politeness_wiki_random.csv\"\n",
    "dataset_name = os.path.splitext(os.path.basename(path))[0]\n",
    "data = pd.read_csv(path, index_col=0)\n",
    "print(\"shape of data: \", data.shape)\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meta.Binary</th>\n",
       "      <th>given_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't spend too much time, and I'm no specia...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;url&gt;. I wonder if anyone will actually suspec...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  meta.Binary  given_label\n",
       "0  I can't spend too much time, and I'm no specia...            0           14\n",
       "1  <url>. I wonder if anyone will actually suspec...            0           13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = data.drop(['true_label', 'true_error'], axis=1)\n",
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_data['given_label']\n",
    "X = training_data.drop(['given_label'], axis=1)\n",
    "\n",
    "###### Add your training code here ###############\n",
    "# model = \n",
    "# model_fit = model.fit(X,y)\n",
    "# predictions = model.predict(X)\n",
    "\n",
    "##### saving the predictions ####################\n",
    "# savepath = \"./../predictions/model_predictions.npy\"\n",
    "# np.save(savepath, np.array(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section section is relevant only if using AutoGluon\n",
    "\n",
    "Uncomment the code in following cells and run to generate output and save to predictions folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "data_without_label = training_data.drop(['given_label'], axis=1)\n",
    "savepath = \"./../trained_models/\"\n",
    "if not os.path.isdir(savepath):\n",
    "    os.mkdir(savepath)\n",
    "\n",
    "predictorArgs = {\n",
    "                    \"path\"             : savepath, \n",
    "                    \"label\"            : 'given_label',\n",
    "                    \"eval_metric\"      : 'r2',\n",
    "                    \"problem_type\"     : 'regression'\n",
    "                }\n",
    "\n",
    "hyperparameters = { \n",
    "                    'GBM'   : {}, \n",
    "                    'FASTAI': {}, \n",
    "                    'RF'    : {'criterion': 'squared_error', \n",
    "                                'ag_args': {'name_suffix': 'MSE', \n",
    "                                'problem_types': ['regression', 'quantile']}}\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./../trained_models/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./../trained_models/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    1311\n",
      "Train Data Columns: 2\n",
      "Label Column: given_label\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1280.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 164\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 164 to 153 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['meta.Binary']\n",
      "\t\t('object', ['text']) : 1 | ['text']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :   1 | ['text']\n",
      "\t\t('int', [])                         :   1 | ['meta.Binary']\n",
      "\t\t('int', ['binned', 'text_special']) :  22 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 154 | ['__nlp__.about', '__nlp__.added', '__nlp__.all', '__nlp__.also', '__nlp__.am', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t2 features in original data used to generate 178 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.44 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1048, Val Rows: 263\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t0.4621\t = Validation score   (r2)\n",
      "\t1.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t0.4386\t = Validation score   (r2)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 5: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "\t0.4658\t = Validation score   (r2)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.482\t = Validation score   (r2)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.74s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./../trained_models/\")\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>0.841904</td>\n",
       "      <td>0.438618</td>\n",
       "      <td>0.038365</td>\n",
       "      <td>0.026688</td>\n",
       "      <td>1.079339</td>\n",
       "      <td>0.038365</td>\n",
       "      <td>0.026688</td>\n",
       "      <td>1.079339</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.633514</td>\n",
       "      <td>0.462138</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>1.835354</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>1.835354</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.620139</td>\n",
       "      <td>0.481958</td>\n",
       "      <td>0.061219</td>\n",
       "      <td>0.036565</td>\n",
       "      <td>4.230643</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.029419</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.538823</td>\n",
       "      <td>0.465791</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>1.286531</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>1.286531</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0      RandomForestMSE    0.841904   0.438618        0.038365       0.026688   \n",
       "1             LightGBM    0.633514   0.462138        0.005256       0.002620   \n",
       "2  WeightedEnsemble_L2    0.620139   0.481958        0.061219       0.036565   \n",
       "3      NeuralNetFastAI    0.538823   0.465791        0.014113       0.007087   \n",
       "\n",
       "   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0  1.079339                 0.038365                0.026688   \n",
       "1  1.835354                 0.005256                0.002620   \n",
       "2  4.230643                 0.003485                0.000170   \n",
       "3  1.286531                 0.014113                0.007087   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           1.079339            1       True          2  \n",
       "1           1.835354            1       True          1  \n",
       "2           0.029419            2       True          4  \n",
       "3           1.286531            1       True          3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor(**predictorArgs)\n",
    "predictor.fit(training_data, hyperparameters=hyperparameters)\n",
    "leaderboard = predictor.leaderboard(training_data, silent=True)\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./../trained_models/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./../trained_models/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    1311\n",
      "Train Data Columns: 2\n",
      "Label Column: given_label\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1271.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 164\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 164 to 85 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['meta.Binary']\n",
      "\t\t('object', ['text']) : 1 | ['text']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['text']\n",
      "\t\t('int', [])                         :  1 | ['meta.Binary']\n",
      "\t\t('int', ['binned', 'text_special']) : 22 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 86 | ['__nlp__.about', '__nlp__.all', '__nlp__.an', '__nlp__.and', '__nlp__.any', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t2 features in original data used to generate 110 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tWill use sequential fold fitting strategy because Darwin OS does not yet support parallel folding.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.4819\t = Validation score   (r2)\n",
      "\t10.29s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t0.4618\t = Validation score   (r2)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 7: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 7: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 5: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 6: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "\t0.4718\t = Validation score   (r2)\n",
      "\t4.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.4987\t = Validation score   (r2)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.02s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./../trained_models/\")\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>0.925830</td>\n",
       "      <td>0.461780</td>\n",
       "      <td>0.039847</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>0.665631</td>\n",
       "      <td>0.039847</td>\n",
       "      <td>0.060613</td>\n",
       "      <td>0.665631</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.685110</td>\n",
       "      <td>0.481936</td>\n",
       "      <td>0.042976</td>\n",
       "      <td>0.037055</td>\n",
       "      <td>10.285733</td>\n",
       "      <td>0.042976</td>\n",
       "      <td>0.037055</td>\n",
       "      <td>10.285733</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.681938</td>\n",
       "      <td>0.498680</td>\n",
       "      <td>0.185881</td>\n",
       "      <td>0.131102</td>\n",
       "      <td>15.417005</td>\n",
       "      <td>0.001273</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.032823</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.600704</td>\n",
       "      <td>0.471798</td>\n",
       "      <td>0.101785</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>4.432818</td>\n",
       "      <td>0.101785</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>4.432818</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val  pred_time_test  \\\n",
       "0  RandomForestMSE_BAG_L1    0.925830   0.461780        0.039847   \n",
       "1         LightGBM_BAG_L1    0.685110   0.481936        0.042976   \n",
       "2     WeightedEnsemble_L2    0.681938   0.498680        0.185881   \n",
       "3  NeuralNetFastAI_BAG_L1    0.600704   0.471798        0.101785   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.060613   0.665631                 0.039847                0.060613   \n",
       "1       0.037055  10.285733                 0.042976                0.037055   \n",
       "2       0.131102  15.417005                 0.001273                0.000164   \n",
       "3       0.033270   4.432818                 0.101785                0.033270   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.665631            1       True          2  \n",
       "1          10.285733            1       True          1  \n",
       "2           0.032823            2       True          4  \n",
       "3           4.432818            1       True          3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_cv = TabularPredictor(**predictorArgs) \n",
    "predictor_cv.fit(training_data, presets=\"best_quality\", num_stack_levels= 0, hyperparameters=hyperparameters)\n",
    "leaderboard_cv = predictor_cv.leaderboard(training_data, silent=True)\n",
    "leaderboard_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting and saving arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {  'normal'            : list(leaderboard['model']), \n",
    "            'crossValidation'   : list(np.append(leaderboard_cv['model'], ['oof']))}\n",
    "\n",
    "predictors = { 'normal'          : predictor, \n",
    "               'crossValidation' : predictor_cv}\n",
    "\n",
    "# check if path is available, else create it. \n",
    "pred_path = \"./../predictions/\"\n",
    "if not os.path.isdir(pred_path):\n",
    "    os.mkdir(pred_path)\n",
    "\n",
    "for model_type in models.keys():\n",
    "    if model_type == \"normal\": \n",
    "        for model in models[model_type]:\n",
    "            savepath = os.path.join(pred_path, model+\".npy\")\n",
    "            predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "            np.save(savepath, np.array(predictions))\n",
    "    elif model_type == \"crossValidation\":\n",
    "        for model in models[model_type]:\n",
    "            if model == \"oof\":\n",
    "                predictions = predictors[model_type].get_oof_pred()\n",
    "                savepath = os.path.join(pred_path, model+\".npy\")\n",
    "            elif model in models['normal']:\n",
    "                predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "                savepath = os.path.join(pred_path, model+\"_CV.npy\")\n",
    "            else: \n",
    "                predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "                savepath = os.path.join(pred_path, model+\".npy\")\n",
    "\n",
    "            np.save(savepath, np.array(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ec5147ab5bbc74496efa97232afb589cdbea0c15a514f90cf1ef23ccb9e83f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
