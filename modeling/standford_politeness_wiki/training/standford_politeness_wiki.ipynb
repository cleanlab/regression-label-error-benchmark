{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P ./../../../dataset/ -nc https://cleanlab-public.s3.amazonaws.com/RegressionBenchmark/standford_politeness_wiki.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:  (1311, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_error</th>\n",
       "      <th>text</th>\n",
       "      <th>meta.Binary</th>\n",
       "      <th>true_label</th>\n",
       "      <th>given_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625810</th>\n",
       "      <td>0</td>\n",
       "      <td>I can't spend too much time, and I'm no specia...</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73465</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;url&gt;. I wonder if anyone will actually suspec...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590458</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok, that's no problem. Can you recommend any o...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626004</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, that was an example as I am adding Infob...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321142</th>\n",
       "      <td>0</td>\n",
       "      <td>Hi, i saw in a lot of biography articles are u...</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        true_error                                               text  \\\n",
       "id                                                                      \n",
       "625810           0  I can't spend too much time, and I'm no specia...   \n",
       "73465            0  <url>. I wonder if anyone will actually suspec...   \n",
       "590458           0  Ok, that's no problem. Can you recommend any o...   \n",
       "626004           1  Well, that was an example as I am adding Infob...   \n",
       "321142           0  Hi, i saw in a lot of biography articles are u...   \n",
       "\n",
       "        meta.Binary  true_label  given_label  \n",
       "id                                            \n",
       "625810            0        17.0         11.0  \n",
       "73465             0        13.0         13.0  \n",
       "590458            1        17.0         20.0  \n",
       "626004            0        13.0         20.0  \n",
       "321142            0        17.0          9.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./../../../dataset/standford_politeness_wiki.csv\"\n",
    "dataset_name = os.path.splitext(os.path.basename(path))[0]\n",
    "data = pd.read_csv(path, index_col=0)\n",
    "print(\"shape of data: \", data.shape)\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meta.Binary</th>\n",
       "      <th>given_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625810</th>\n",
       "      <td>I can't spend too much time, and I'm no specia...</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73465</th>\n",
       "      <td>&lt;url&gt;. I wonder if anyone will actually suspec...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  meta.Binary  \\\n",
       "id                                                                       \n",
       "625810  I can't spend too much time, and I'm no specia...            0   \n",
       "73465   <url>. I wonder if anyone will actually suspec...            0   \n",
       "\n",
       "        given_label  \n",
       "id                   \n",
       "625810         11.0  \n",
       "73465          13.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = data.drop(['true_label', 'true_error'], axis=1)\n",
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_data['given_label']\n",
    "X = training_data.drop(['given_label'], axis=1)\n",
    "\n",
    "###### Add your training code here ###############\n",
    "# model = \n",
    "# model_fit = model.fit(X,y)\n",
    "# predictions = model.predict(X)\n",
    "\n",
    "##### saving the predictions ####################\n",
    "# savepath = \"./../predictions/model_predictions.npy\"\n",
    "# np.save(savepath, np.array(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section section is relevant only if using AutoGluon\n",
    "\n",
    "Uncomment the code in following cells and run to generate output and save to predictions folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "data_without_label = training_data.drop(['given_label'], axis=1)\n",
    "savepath = \"./../trained_models/\"\n",
    "if not os.path.isdir(savepath):\n",
    "    os.mkdir(savepath)\n",
    "\n",
    "predictorArgs = {\n",
    "                    \"path\"             : savepath, \n",
    "                    \"label\"            : 'given_label',\n",
    "                    \"eval_metric\"      : 'r2',\n",
    "                    \"problem_type\"     : 'regression'\n",
    "                }\n",
    "\n",
    "hyperparameters = { \n",
    "                    'GBM'   : {}, \n",
    "                    'FASTAI': {}, \n",
    "                    'RF'    : {'criterion': 'squared_error', \n",
    "                                'ag_args': {'name_suffix': 'MSE', \n",
    "                                'problem_types': ['regression', 'quantile']}}\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./../trained_models/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./../trained_models/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    1311\n",
      "Train Data Columns: 2\n",
      "Label Column: given_label\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2523.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 164\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['meta.Binary']\n",
      "\t\t('object', ['text']) : 1 | ['text']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :   1 | ['text']\n",
      "\t\t('int', [])                         :   1 | ['meta.Binary']\n",
      "\t\t('int', ['binned', 'text_special']) :  22 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 165 | ['__nlp__.about', '__nlp__.added', '__nlp__.all', '__nlp__.also', '__nlp__.am', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t2 features in original data used to generate 189 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.47 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1048, Val Rows: 263\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t0.2842\t = Validation score   (r2)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t0.2911\t = Validation score   (r2)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 7: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "\t0.3151\t = Validation score   (r2)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3226\t = Validation score   (r2)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.96s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./../trained_models/\")\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>0.780762</td>\n",
       "      <td>0.291145</td>\n",
       "      <td>0.057227</td>\n",
       "      <td>0.042443</td>\n",
       "      <td>1.036654</td>\n",
       "      <td>0.057227</td>\n",
       "      <td>0.042443</td>\n",
       "      <td>1.036654</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.590110</td>\n",
       "      <td>0.322621</td>\n",
       "      <td>0.078473</td>\n",
       "      <td>0.051964</td>\n",
       "      <td>4.558538</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.027107</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.471101</td>\n",
       "      <td>0.284203</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>2.086543</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>2.086543</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.449496</td>\n",
       "      <td>0.315095</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>1.408234</td>\n",
       "      <td>0.014442</td>\n",
       "      <td>0.007286</td>\n",
       "      <td>1.408234</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0      RandomForestMSE    0.780762   0.291145        0.057227       0.042443   \n",
       "1  WeightedEnsemble_L2    0.590110   0.322621        0.078473       0.051964   \n",
       "2             LightGBM    0.471101   0.284203        0.003873       0.002049   \n",
       "3      NeuralNetFastAI    0.449496   0.315095        0.014442       0.007286   \n",
       "\n",
       "   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0  1.036654                 0.057227                0.042443   \n",
       "1  4.558538                 0.002931                0.000186   \n",
       "2  2.086543                 0.003873                0.002049   \n",
       "3  1.408234                 0.014442                0.007286   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           1.036654            1       True          2  \n",
       "1           0.027107            2       True          4  \n",
       "2           2.086543            1       True          1  \n",
       "3           1.408234            1       True          3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor(**predictorArgs)\n",
    "predictor.fit(training_data, hyperparameters=hyperparameters)\n",
    "leaderboard = predictor.leaderboard(training_data, silent=True)\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./../trained_models/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./../trained_models/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    1311\n",
      "Train Data Columns: 2\n",
      "Label Column: given_label\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2447.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 164\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 164 to 146 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['meta.Binary']\n",
      "\t\t('object', ['text']) : 1 | ['text']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :   1 | ['text']\n",
      "\t\t('int', [])                         :   1 | ['meta.Binary']\n",
      "\t\t('int', ['binned', 'text_special']) :  22 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 147 | ['__nlp__.about', '__nlp__.added', '__nlp__.all', '__nlp__.also', '__nlp__.am', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t2 features in original data used to generate 171 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.43 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.35s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tWill use sequential fold fitting strategy because Darwin OS does not yet support parallel folding.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3445\t = Validation score   (r2)\n",
      "\t11.83s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t0.352\t = Validation score   (r2)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 9: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 8: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 6: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 5: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 8: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "\t0.3412\t = Validation score   (r2)\n",
      "\t6.35s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3733\t = Validation score   (r2)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.91s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./../trained_models/\")\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>0.910873</td>\n",
       "      <td>0.352036</td>\n",
       "      <td>0.058100</td>\n",
       "      <td>0.064191</td>\n",
       "      <td>1.065948</td>\n",
       "      <td>0.058100</td>\n",
       "      <td>0.064191</td>\n",
       "      <td>1.065948</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.719251</td>\n",
       "      <td>0.373323</td>\n",
       "      <td>0.231820</td>\n",
       "      <td>0.126837</td>\n",
       "      <td>19.277947</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.029936</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.594224</td>\n",
       "      <td>0.344514</td>\n",
       "      <td>0.064609</td>\n",
       "      <td>0.019843</td>\n",
       "      <td>11.828509</td>\n",
       "      <td>0.064609</td>\n",
       "      <td>0.019843</td>\n",
       "      <td>11.828509</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.493886</td>\n",
       "      <td>0.341153</td>\n",
       "      <td>0.107909</td>\n",
       "      <td>0.042647</td>\n",
       "      <td>6.353554</td>\n",
       "      <td>0.107909</td>\n",
       "      <td>0.042647</td>\n",
       "      <td>6.353554</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val  pred_time_test  \\\n",
       "0  RandomForestMSE_BAG_L1    0.910873   0.352036        0.058100   \n",
       "1     WeightedEnsemble_L2    0.719251   0.373323        0.231820   \n",
       "2         LightGBM_BAG_L1    0.594224   0.344514        0.064609   \n",
       "3  NeuralNetFastAI_BAG_L1    0.493886   0.341153        0.107909   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.064191   1.065948                 0.058100                0.064191   \n",
       "1       0.126837  19.277947                 0.001203                0.000156   \n",
       "2       0.019843  11.828509                 0.064609                0.019843   \n",
       "3       0.042647   6.353554                 0.107909                0.042647   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           1.065948            1       True          2  \n",
       "1           0.029936            2       True          4  \n",
       "2          11.828509            1       True          1  \n",
       "3           6.353554            1       True          3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_cv = TabularPredictor(**predictorArgs) \n",
    "predictor_cv.fit(training_data, presets=\"best_quality\", num_stack_levels= 0, hyperparameters=hyperparameters)\n",
    "leaderboard_cv = predictor_cv.leaderboard(training_data, silent=True)\n",
    "leaderboard_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting and saving arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {  'normal'            : list(leaderboard['model']), \n",
    "            'crossValidation'   : list(np.append(leaderboard_cv['model'], ['oof']))}\n",
    "\n",
    "predictors = { 'normal'          : predictor, \n",
    "               'crossValidation' : predictor_cv}\n",
    "\n",
    "# check if path is available, else create it. \n",
    "pred_path = \"./../predictions/\"\n",
    "if not os.path.isdir(pred_path):\n",
    "    os.mkdir(pred_path)\n",
    "\n",
    "for model_type in models.keys():\n",
    "    if model_type == \"normal\": \n",
    "        for model in models[model_type]:\n",
    "            savepath = os.path.join(pred_path, model+\".npy\")\n",
    "            predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "            np.save(savepath, np.array(predictions))\n",
    "    elif model_type == \"crossValidation\":\n",
    "        for model in models[model_type]:\n",
    "            if model == \"oof\":\n",
    "                predictions = predictors[model_type].get_oof_pred()\n",
    "                savepath = os.path.join(pred_path, model+\".npy\")\n",
    "            elif model in models['normal']:\n",
    "                predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "                savepath = os.path.join(pred_path, model+\"_CV.npy\")\n",
    "            else: \n",
    "                predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "                savepath = os.path.join(pred_path, model+\".npy\")\n",
    "\n",
    "            np.save(savepath, np.array(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('cleanlab_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ec5147ab5bbc74496efa97232afb589cdbea0c15a514f90cf1ef23ccb9e83f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
