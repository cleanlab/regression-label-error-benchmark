{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P ./../../../dataset/ -nc https://cleanlab-public.s3.amazonaws.com/RegressionBenchmark/standford_politeness_stack.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:  (6603, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_error</th>\n",
       "      <th>text</th>\n",
       "      <th>meta.Binary</th>\n",
       "      <th>true_label</th>\n",
       "      <th>given_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Can you explain more in detail, what should I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Will expressions always be unambiguously paren...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>how are you resolving function pointers? I am ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the definition of `buffer`? Is it a lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Is `A` a global variable?  What is x?</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    true_error                                               text  \\\n",
       "id                                                                  \n",
       "0            0  Can you explain more in detail, what should I ...   \n",
       "1            0  Will expressions always be unambiguously paren...   \n",
       "2            0  how are you resolving function pointers? I am ...   \n",
       "3            0  What is the definition of `buffer`? Is it a lo...   \n",
       "4            0              Is `A` a global variable?  What is x?   \n",
       "\n",
       "    meta.Binary  true_label  given_label  \n",
       "id                                        \n",
       "0             0        15.0         12.0  \n",
       "1             0        13.0         18.0  \n",
       "2             0        15.0         13.0  \n",
       "3             0        13.0         19.0  \n",
       "4             1        16.0         13.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./../../../dataset/standford_politeness_stack.csv\"\n",
    "dataset_name = os.path.splitext(os.path.basename(path))[0]\n",
    "data = pd.read_csv(path, index_col=0)\n",
    "print(\"shape of data: \", data.shape)\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meta.Binary</th>\n",
       "      <th>given_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you explain more in detail, what should I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will expressions always be unambiguously paren...</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  meta.Binary  \\\n",
       "id                                                                   \n",
       "0   Can you explain more in detail, what should I ...            0   \n",
       "1   Will expressions always be unambiguously paren...            0   \n",
       "\n",
       "    given_label  \n",
       "id               \n",
       "0          12.0  \n",
       "1          18.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = data.drop(['true_label', 'true_error'], axis=1)\n",
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_data['given_label']\n",
    "X = training_data.drop(['given_label'], axis=1)\n",
    "\n",
    "###### Add your training code here ###############\n",
    "# model = \n",
    "# model_fit = model.fit(X,y)\n",
    "# predictions = model.predict(X)\n",
    "\n",
    "##### saving the predictions ####################\n",
    "# savepath = \"./../predictions/model_predictions.npy\"\n",
    "# np.save(savepath, np.array(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section section is relevant only if using AutoGluon\n",
    "\n",
    "Uncomment the code in following cells and run to generate output and save to predictions folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "data_without_label = training_data.drop(['given_label'], axis=1)\n",
    "savepath = \"./../trained_models/\"\n",
    "if not os.path.isdir(savepath):\n",
    "    os.mkdir(savepath)\n",
    "\n",
    "predictorArgs = {\n",
    "                    \"path\"             : savepath, \n",
    "                    \"label\"            : 'given_label',\n",
    "                    \"eval_metric\"      : 'r2',\n",
    "                    \"problem_type\"     : 'regression'\n",
    "                }\n",
    "\n",
    "hyperparameters = { \n",
    "                    'GBM'   : {}, \n",
    "                    'FASTAI': {}, \n",
    "                    'RF'    : {'criterion': 'squared_error', \n",
    "                                'ag_args': {'name_suffix': 'MSE', \n",
    "                                'problem_types': ['regression', 'quantile']}}\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./../trained_models/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./../trained_models/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    6603\n",
      "Train Data Columns: 2\n",
      "Label Column: given_label\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1709.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.18 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 860\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 860 to 765 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['meta.Binary']\n",
      "\t\t('object', ['text']) : 1 | ['text']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :   1 | ['text']\n",
      "\t\t('int', [])                         :   1 | ['meta.Binary']\n",
      "\t\t('int', ['binned', 'text_special']) :  30 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 766 | ['__nlp__.10', '__nlp__.100', '__nlp__.able', '__nlp__.able to', '__nlp__.about', ...]\n",
      "\t1.1s = Fit runtime\n",
      "\t2 features in original data used to generate 798 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 10.37 MB (0.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 5942, Val Rows: 661\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t0.0995\t = Validation score   (r2)\n",
      "\t1.88s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t0.0669\t = Validation score   (r2)\n",
      "\t29.68s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "\t0.0996\t = Validation score   (r2)\n",
      "\t3.8s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1085\t = Validation score   (r2)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 36.67s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./../trained_models/\")\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>0.801878</td>\n",
       "      <td>0.066884</td>\n",
       "      <td>0.174460</td>\n",
       "      <td>0.030841</td>\n",
       "      <td>29.677402</td>\n",
       "      <td>0.174460</td>\n",
       "      <td>0.030841</td>\n",
       "      <td>29.677402</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.283338</td>\n",
       "      <td>0.108523</td>\n",
       "      <td>0.270816</td>\n",
       "      <td>0.044095</td>\n",
       "      <td>35.385337</td>\n",
       "      <td>0.011829</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.028306</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.226425</td>\n",
       "      <td>0.099457</td>\n",
       "      <td>0.038924</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>1.876754</td>\n",
       "      <td>0.038924</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>1.876754</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.220020</td>\n",
       "      <td>0.099589</td>\n",
       "      <td>0.045603</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>3.802875</td>\n",
       "      <td>0.045603</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>3.802875</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0      RandomForestMSE    0.801878   0.066884        0.174460       0.030841   \n",
       "1  WeightedEnsemble_L2    0.283338   0.108523        0.270816       0.044095   \n",
       "2             LightGBM    0.226425   0.099457        0.038924       0.004814   \n",
       "3      NeuralNetFastAI    0.220020   0.099589        0.045603       0.008281   \n",
       "\n",
       "    fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0  29.677402                 0.174460                0.030841   \n",
       "1  35.385337                 0.011829                0.000159   \n",
       "2   1.876754                 0.038924                0.004814   \n",
       "3   3.802875                 0.045603                0.008281   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0          29.677402            1       True          2  \n",
       "1           0.028306            2       True          4  \n",
       "2           1.876754            1       True          1  \n",
       "3           3.802875            1       True          3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor(**predictorArgs)\n",
    "predictor.fit(training_data, hyperparameters=hyperparameters)\n",
    "leaderboard = predictor.leaderboard(training_data, silent=True)\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./../trained_models/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./../trained_models/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    6603\n",
      "Train Data Columns: 2\n",
      "Label Column: given_label\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1469.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.18 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 860\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 860 to 277 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['meta.Binary']\n",
      "\t\t('object', ['text']) : 1 | ['text']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :   1 | ['text']\n",
      "\t\t('int', [])                         :   1 | ['meta.Binary']\n",
      "\t\t('int', ['binned', 'text_special']) :  30 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 278 | ['__nlp__.about', '__nlp__.actually', '__nlp__.add', '__nlp__.after', '__nlp__.all', ...]\n",
      "\t1.0s = Fit runtime\n",
      "\t2 features in original data used to generate 310 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.93 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tWill use sequential fold fitting strategy because Darwin OS does not yet support parallel folding.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.1479\t = Validation score   (r2)\n",
      "\t5.91s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t0.1233\t = Validation score   (r2)\n",
      "\t9.21s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 0: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 6: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 5: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 4: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "\t0.1387\t = Validation score   (r2)\n",
      "\t19.87s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.1544\t = Validation score   (r2)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 36.81s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./../trained_models/\")\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>0.879445</td>\n",
       "      <td>0.123281</td>\n",
       "      <td>0.148648</td>\n",
       "      <td>0.402152</td>\n",
       "      <td>9.210376</td>\n",
       "      <td>0.148648</td>\n",
       "      <td>0.402152</td>\n",
       "      <td>9.210376</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.334684</td>\n",
       "      <td>0.154421</td>\n",
       "      <td>0.547404</td>\n",
       "      <td>0.520511</td>\n",
       "      <td>35.048301</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.050995</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.236060</td>\n",
       "      <td>0.147926</td>\n",
       "      <td>0.118025</td>\n",
       "      <td>0.039639</td>\n",
       "      <td>5.912786</td>\n",
       "      <td>0.118025</td>\n",
       "      <td>0.039639</td>\n",
       "      <td>5.912786</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.200076</td>\n",
       "      <td>0.138733</td>\n",
       "      <td>0.279418</td>\n",
       "      <td>0.078544</td>\n",
       "      <td>19.874143</td>\n",
       "      <td>0.279418</td>\n",
       "      <td>0.078544</td>\n",
       "      <td>19.874143</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val  pred_time_test  \\\n",
       "0  RandomForestMSE_BAG_L1    0.879445   0.123281        0.148648   \n",
       "1     WeightedEnsemble_L2    0.334684   0.154421        0.547404   \n",
       "2         LightGBM_BAG_L1    0.236060   0.147926        0.118025   \n",
       "3  NeuralNetFastAI_BAG_L1    0.200076   0.138733        0.279418   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.402152   9.210376                 0.148648                0.402152   \n",
       "1       0.520511  35.048301                 0.001313                0.000176   \n",
       "2       0.039639   5.912786                 0.118025                0.039639   \n",
       "3       0.078544  19.874143                 0.279418                0.078544   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           9.210376            1       True          2  \n",
       "1           0.050995            2       True          4  \n",
       "2           5.912786            1       True          1  \n",
       "3          19.874143            1       True          3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_cv = TabularPredictor(**predictorArgs) \n",
    "predictor_cv.fit(training_data, presets=\"best_quality\", num_stack_levels= 0, hyperparameters=hyperparameters)\n",
    "leaderboard_cv = predictor_cv.leaderboard(training_data, silent=True)\n",
    "leaderboard_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting and saving arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {  'normal'            : list(leaderboard['model']), \n",
    "            'crossValidation'   : list(np.append(leaderboard_cv['model'], ['oof']))}\n",
    "\n",
    "predictors = { 'normal'          : predictor, \n",
    "               'crossValidation' : predictor_cv}\n",
    "\n",
    "# check if path is available, else create it. \n",
    "pred_path = \"./../predictions/\"\n",
    "if not os.path.isdir(pred_path):\n",
    "    os.mkdir(pred_path)\n",
    "\n",
    "for model_type in models.keys():\n",
    "    if model_type == \"normal\": \n",
    "        for model in models[model_type]:\n",
    "            savepath = os.path.join(pred_path, model+\".npy\")\n",
    "            predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "            np.save(savepath, np.array(predictions))\n",
    "    elif model_type == \"crossValidation\":\n",
    "        for model in models[model_type]:\n",
    "            if model == \"oof\":\n",
    "                predictions = predictors[model_type].get_oof_pred()\n",
    "                savepath = os.path.join(pred_path, model+\".npy\")\n",
    "            elif model in models['normal']:\n",
    "                predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "                savepath = os.path.join(pred_path, model+\"_CV.npy\")\n",
    "            else: \n",
    "                predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "                savepath = os.path.join(pred_path, model+\".npy\")\n",
    "\n",
    "            np.save(savepath, np.array(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ec5147ab5bbc74496efa97232afb589cdbea0c15a514f90cf1ef23ccb9e83f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
