{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-21 10:33:28--  https://cleanlab-public.s3.amazonaws.com/RegressionBenchmark/stanford_politeness_wiki_furthest.csv\n",
      "Resolving cleanlab-public.s3.amazonaws.com (cleanlab-public.s3.amazonaws.com)... 52.216.211.65, 3.5.11.209, 52.216.178.219, ...\n",
      "Connecting to cleanlab-public.s3.amazonaws.com (cleanlab-public.s3.amazonaws.com)|52.216.211.65|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 196435 (192K) [text/csv]\n",
      "Saving to: './../../../dataset/stanford_politeness_wiki_furthest.csv'\n",
      "\n",
      "stanford_politeness 100%[===================>] 191.83K   548KB/s    in 0.3s    \n",
      "\n",
      "2022-12-21 10:33:46 (548 KB/s) - './../../../dataset/stanford_politeness_wiki_furthest.csv' saved [196435/196435]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ./../../../dataset/ -nc https://cleanlab-public.s3.amazonaws.com/RegressionBenchmark/stanford_politeness_wiki_furthest.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data:  (1311, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meta.Binary</th>\n",
       "      <th>true_label</th>\n",
       "      <th>given_label</th>\n",
       "      <th>true_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't spend too much time, and I'm no specia...</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;url&gt;. I wonder if anyone will actually suspec...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok, that's no problem. Can you recommend any o...</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well, that was an example as I am adding Infob...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi, i saw in a lot of biography articles are u...</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  meta.Binary  true_label  \\\n",
       "0  I can't spend too much time, and I'm no specia...            0        17.0   \n",
       "1  <url>. I wonder if anyone will actually suspec...            0        13.0   \n",
       "2  Ok, that's no problem. Can you recommend any o...            1        17.0   \n",
       "3  Well, that was an example as I am adding Infob...            0        13.0   \n",
       "4  Hi, i saw in a lot of biography articles are u...            0        17.0   \n",
       "\n",
       "   given_label  true_error  \n",
       "0         11.0           0  \n",
       "1         13.0           0  \n",
       "2         20.0           0  \n",
       "3         20.0           1  \n",
       "4          9.0           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./../../../dataset/stanford_politeness_wiki_furthest.csv\"\n",
    "dataset_name = os.path.splitext(os.path.basename(path))[0]\n",
    "data = pd.read_csv(path, index_col=0)\n",
    "print(\"shape of data: \", data.shape)\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meta.Binary</th>\n",
       "      <th>given_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't spend too much time, and I'm no specia...</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;url&gt;. I wonder if anyone will actually suspec...</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  meta.Binary  given_label\n",
       "0  I can't spend too much time, and I'm no specia...            0         11.0\n",
       "1  <url>. I wonder if anyone will actually suspec...            0         13.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = data.drop(['true_label', 'true_error'], axis=1)\n",
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_data['given_label']\n",
    "X = training_data.drop(['given_label'], axis=1)\n",
    "\n",
    "###### Add your training code here ###############\n",
    "# model = \n",
    "# model_fit = model.fit(X,y)\n",
    "# predictions = model.predict(X)\n",
    "\n",
    "##### saving the predictions ####################\n",
    "# savepath = \"./../predictions/model_predictions.npy\"\n",
    "# np.save(savepath, np.array(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section section is relevant only if using AutoGluon\n",
    "\n",
    "Uncomment the code in following cells and run to generate output and save to predictions folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "data_without_label = training_data.drop(['given_label'], axis=1)\n",
    "savepath = \"./../trained_models/\"\n",
    "if not os.path.isdir(savepath):\n",
    "    os.mkdir(savepath)\n",
    "\n",
    "predictorArgs = {\n",
    "                    \"path\"             : savepath, \n",
    "                    \"label\"            : 'given_label',\n",
    "                    \"eval_metric\"      : 'r2',\n",
    "                    \"problem_type\"     : 'regression'\n",
    "                }\n",
    "\n",
    "hyperparameters = { \n",
    "                    'GBM'   : {}, \n",
    "                    'FASTAI': {}, \n",
    "                    'RF'    : {'criterion': 'squared_error', \n",
    "                                'ag_args': {'name_suffix': 'MSE', \n",
    "                                'problem_types': ['regression', 'quantile']}}\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./../trained_models/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./../trained_models/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    1311\n",
      "Train Data Columns: 2\n",
      "Label Column: given_label\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1319.42 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 164\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 164 to 158 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['meta.Binary']\n",
      "\t\t('object', ['text']) : 1 | ['text']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :   1 | ['text']\n",
      "\t\t('int', [])                         :   1 | ['meta.Binary']\n",
      "\t\t('int', ['binned', 'text_special']) :  22 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 159 | ['__nlp__.about', '__nlp__.added', '__nlp__.all', '__nlp__.also', '__nlp__.am', ...]\n",
      "\t0.4s = Fit runtime\n",
      "\t2 features in original data used to generate 183 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1048, Val Rows: 263\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t0.2783\t = Validation score   (r2)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t0.2952\t = Validation score   (r2)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 7: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "\t0.3151\t = Validation score   (r2)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3235\t = Validation score   (r2)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.13s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./../trained_models/\")\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>0.782212</td>\n",
       "      <td>0.295220</td>\n",
       "      <td>0.033516</td>\n",
       "      <td>0.021059</td>\n",
       "      <td>0.783403</td>\n",
       "      <td>0.033516</td>\n",
       "      <td>0.021059</td>\n",
       "      <td>0.783403</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.607446</td>\n",
       "      <td>0.323534</td>\n",
       "      <td>0.048302</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>2.237615</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.031238</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.497689</td>\n",
       "      <td>0.278344</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>1.438684</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>1.438684</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.449496</td>\n",
       "      <td>0.315095</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.010317</td>\n",
       "      <td>1.422973</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.010317</td>\n",
       "      <td>1.422973</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  score_val  pred_time_test  pred_time_val  \\\n",
       "0      RandomForestMSE    0.782212   0.295220        0.033516       0.021059   \n",
       "1  WeightedEnsemble_L2    0.607446   0.323534        0.048302       0.031636   \n",
       "2             LightGBM    0.497689   0.278344        0.005088       0.002148   \n",
       "3      NeuralNetFastAI    0.449496   0.315095        0.012289       0.010317   \n",
       "\n",
       "   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0  0.783403                 0.033516                0.021059   \n",
       "1  2.237615                 0.002497                0.000261   \n",
       "2  1.438684                 0.005088                0.002148   \n",
       "3  1.422973                 0.012289                0.010317   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.783403            1       True          2  \n",
       "1           0.031238            2       True          4  \n",
       "2           1.438684            1       True          1  \n",
       "3           1.422973            1       True          3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor(**predictorArgs)\n",
    "predictor.fit(training_data, hyperparameters=hyperparameters)\n",
    "leaderboard = predictor.leaderboard(training_data, silent=True)\n",
    "leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./../trained_models/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./../trained_models/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    1311\n",
      "Train Data Columns: 2\n",
      "Label Column: given_label\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1321.67 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 164\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 164 to 85 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 1 | ['meta.Binary']\n",
      "\t\t('object', ['text']) : 1 | ['text']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['text']\n",
      "\t\t('int', [])                         :  1 | ['meta.Binary']\n",
      "\t\t('int', ['binned', 'text_special']) : 22 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 86 | ['__nlp__.about', '__nlp__.all', '__nlp__.an', '__nlp__.and', '__nlp__.any', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t2 features in original data used to generate 110 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.3s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 3 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tWill use sequential fold fitting strategy because Darwin OS does not yet support parallel folding.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.3403\t = Validation score   (r2)\n",
      "\t4.69s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t0.3406\t = Validation score   (r2)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 9: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 8: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 6: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 5: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "No improvement since epoch 8: early stopping\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "\t0.3412\t = Validation score   (r2)\n",
      "\t4.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.3677\t = Validation score   (r2)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.21s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./../trained_models/\")\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>0.909265</td>\n",
       "      <td>0.340596</td>\n",
       "      <td>0.048730</td>\n",
       "      <td>0.058147</td>\n",
       "      <td>0.620326</td>\n",
       "      <td>0.048730</td>\n",
       "      <td>0.058147</td>\n",
       "      <td>0.620326</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.669053</td>\n",
       "      <td>0.367674</td>\n",
       "      <td>0.188345</td>\n",
       "      <td>0.107723</td>\n",
       "      <td>9.694040</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.033570</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>0.340268</td>\n",
       "      <td>0.044289</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>4.689304</td>\n",
       "      <td>0.044289</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>4.689304</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.493886</td>\n",
       "      <td>0.341153</td>\n",
       "      <td>0.094141</td>\n",
       "      <td>0.034725</td>\n",
       "      <td>4.350840</td>\n",
       "      <td>0.094141</td>\n",
       "      <td>0.034725</td>\n",
       "      <td>4.350840</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  score_test  score_val  pred_time_test  \\\n",
       "0  RandomForestMSE_BAG_L1    0.909265   0.340596        0.048730   \n",
       "1     WeightedEnsemble_L2    0.669053   0.367674        0.188345   \n",
       "2         LightGBM_BAG_L1    0.590667   0.340268        0.044289   \n",
       "3  NeuralNetFastAI_BAG_L1    0.493886   0.341153        0.094141   \n",
       "\n",
       "   pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.058147  0.620326                 0.048730                0.058147   \n",
       "1       0.107723  9.694040                 0.001185                0.000167   \n",
       "2       0.014684  4.689304                 0.044289                0.014684   \n",
       "3       0.034725  4.350840                 0.094141                0.034725   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.620326            1       True          2  \n",
       "1           0.033570            2       True          4  \n",
       "2           4.689304            1       True          1  \n",
       "3           4.350840            1       True          3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_cv = TabularPredictor(**predictorArgs) \n",
    "predictor_cv.fit(training_data, presets=\"best_quality\", num_stack_levels= 0, hyperparameters=hyperparameters)\n",
    "leaderboard_cv = predictor_cv.leaderboard(training_data, silent=True)\n",
    "leaderboard_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting and saving arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {  'normal'            : list(leaderboard['model']), \n",
    "            'crossValidation'   : list(np.append(leaderboard_cv['model'], ['oof']))}\n",
    "\n",
    "predictors = { 'normal'          : predictor, \n",
    "               'crossValidation' : predictor_cv}\n",
    "\n",
    "# check if path is available, else create it. \n",
    "pred_path = \"./../predictions/\"\n",
    "if not os.path.isdir(pred_path):\n",
    "    os.mkdir(pred_path)\n",
    "\n",
    "for model_type in models.keys():\n",
    "    if model_type == \"normal\": \n",
    "        for model in models[model_type]:\n",
    "            savepath = os.path.join(pred_path, model+\".npy\")\n",
    "            predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "            np.save(savepath, np.array(predictions))\n",
    "    elif model_type == \"crossValidation\":\n",
    "        for model in models[model_type]:\n",
    "            if model == \"oof\":\n",
    "                predictions = predictors[model_type].get_oof_pred()\n",
    "                savepath = os.path.join(pred_path, model+\".npy\")\n",
    "            elif model in models['normal']:\n",
    "                predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "                savepath = os.path.join(pred_path, model+\"_CV.npy\")\n",
    "            else: \n",
    "                predictions = predictors[model_type].predict(data_without_label, model=model)\n",
    "                savepath = os.path.join(pred_path, model+\".npy\")\n",
    "\n",
    "            np.save(savepath, np.array(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ec5147ab5bbc74496efa97232afb589cdbea0c15a514f90cf1ef23ccb9e83f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
